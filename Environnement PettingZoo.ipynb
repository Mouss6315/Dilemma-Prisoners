{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0405af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "import pygame\n",
    "import pymunk\n",
    "import pymunk.pygame_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ed4b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymunk\n",
      "  Downloading pymunk-6.6.0-cp39-cp39-win_amd64.whl (358 kB)\n",
      "Requirement already satisfied: cffi>=1.15.0 in c:\\users\\mchan\\anaconda3\\lib\\site-packages (from pymunk) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mchan\\anaconda3\\lib\\site-packages (from cffi>=1.15.0->pymunk) (2.21)\n",
      "Installing collected packages: pymunk\n",
      "Successfully installed pymunk-6.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11e5b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting game\n",
      "  Using cached game-0.0.5-py3-none-any.whl (8.3 MB)\n",
      "Installing collected packages: game\n",
      "Successfully installed game-0.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb902fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Games' from 'game' (C:\\Users\\mchan\\anaconda3\\lib\\site-packages\\game\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpettingzoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m agent_selector, wrappers\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpettingzoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parallel_wrapper_fn\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     Games,\n\u001b[0;32m     11\u001b[0m     Prisoners_Dilemma,\n\u001b[0;32m     12\u001b[0m     Samaritans_Dilemma,\n\u001b[0;32m     13\u001b[0m     Stag_Hunt,\n\u001b[0;32m     14\u001b[0m     Chicken,\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Games' from 'game' (C:\\Users\\mchan\\anaconda3\\lib\\site-packages\\game\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete\n",
    "\n",
    "from pettingzoo import AECEnv\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "from pettingzoo.utils.conversions import parallel_wrapper_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c52a1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création des fonctions liées aux jeux\n",
    "class Game:\n",
    "    \"\"\"\n",
    "    Base class for all games.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iters=1000):\n",
    "        \"\"\"\n",
    "        Initializes a new game with the specified number of iterations.\n",
    "\n",
    "        Parameters:\n",
    "        num_iters (int): The number of iterations for the game. Default is 1000.\n",
    "        \"\"\"\n",
    "        self.moves = []\n",
    "        self.num_iters = num_iters\n",
    "\n",
    "    def get_payoff(self):\n",
    "        \"\"\"\n",
    "        Returns the payoff matrix for the game.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_num_iters(self):\n",
    "        \"\"\"\n",
    "        Returns the number of iterations for the game.\n",
    "        \"\"\"\n",
    "        return self.num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d326ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du Jeu\n",
    "class Prisoners_Dilemma(Game):\n",
    "    \"\"\"\n",
    "    Class for the Prisoner's Dilemma game.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes a new Prisoner's Dilemma game.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.COOPERATE = 0\n",
    "        self.DEFECT = 1\n",
    "        self.NONE = 2\n",
    "        self.moves = [\"COOPERATE\", \"DEFECT\", \"None\"]\n",
    "\n",
    "        self.coop = 3.5  # cooperate-cooperate payoff\n",
    "        self.defect = 1  # defect-defect payoff\n",
    "        self.temptation = 5  # cooperate-defect (or vice-versa) tempation payoff\n",
    "        self.sucker = 0  # cooperate-defect (or vice-versa) sucker payoff\n",
    "\n",
    "        self.payoff = {\n",
    "            (self.COOPERATE, self.COOPERATE): (self.coop, self.coop),\n",
    "            (self.COOPERATE, self.DEFECT): (self.sucker, self.temptation),\n",
    "            (self.DEFECT, self.COOPERATE): (self.temptation, self.sucker),\n",
    "            (self.DEFECT, self.DEFECT): (self.defect, self.defect),\n",
    "        }\n",
    "\n",
    "    def get_payoff(self):\n",
    "        \"\"\"\n",
    "        Returns the payoff matrix for the Prisoner's Dilemma game.\n",
    "        \"\"\"\n",
    "        return self.payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93ad8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 0, 'player_1': 5})\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 5, 'player_1': 0})\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 1, 'player_1': 1})\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 1, 'player_1': 1})\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 1, 'player_1': 1})\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 5, 'player_1': 0})\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 0, 'player_1': 5})\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 3.5, 'player_1': 3.5})\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 3.5, 'player_1': 3.5})\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "observations:  defaultdict(<class 'int'>, {'player_0': 0, 'player_1': 5})\n"
     ]
    }
   ],
   "source": [
    "#Création environnenemnt\n",
    "def env(**kwargs):\n",
    "    env = raw_env(**kwargs)\n",
    "    env = wrappers.AssertOutOfBoundsWrapper(env)\n",
    "    env = wrappers.OrderEnforcingWrapper(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "parallel_env = parallel_wrapper_fn(env)\n",
    "\n",
    "\n",
    "class raw_env(AECEnv):\n",
    "    \"\"\"Two-player environment for rock paper scissors.\n",
    "    Expandable environment to rock paper scissors lizard spock action_6 action_7 ...\n",
    "    The observation is simply the last opponent action.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\"],\n",
    "        \"name\": \"simple_pd_v0\",\n",
    "        \"is_parallelizable\": True,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self, game=\"pd\", num_actions=2, max_cycles=15, render_mode=None\n",
    "    ):\n",
    "        self.max_cycles = max_cycles\n",
    "        GAMES = {\n",
    "            \"pd\": Prisoners_Dilemma()\n",
    "        }\n",
    "        self.render_mode = \"human\"\n",
    "        self.name = \"simple_pd_v0\"\n",
    "        self.game = GAMES[game]\n",
    "\n",
    "        self._moves = self.game.moves\n",
    "        # none is last possible action, to satisfy discrete action space\n",
    "        self._none = self.game.NONE\n",
    "\n",
    "        self.agents = [\"player_\" + str(r) for r in range(2)]\n",
    "        self.possible_agents = self.agents[:]\n",
    "        self.agent_name_mapping = dict(\n",
    "            zip(self.agents, list(range(self.num_agents)))\n",
    "        )\n",
    "        self.action_spaces = {\n",
    "            agent: Discrete(num_actions) for agent in self.agents\n",
    "        }\n",
    "        self.observation_spaces = {\n",
    "            agent: Discrete(1 + num_actions) for agent in self.agents\n",
    "        }\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.reinit()\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        return self.observation_spaces[agent]\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        return self.action_spaces[agent]\n",
    "\n",
    "    def reinit(self):\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self._agent_selector = agent_selector(self.agents)\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self._cumulative_rewards = {agent: 0 for agent in self.agents}\n",
    "        self.terminations = {agent: False for agent in self.agents}\n",
    "        self.truncations = {agent: False for agent in self.agents}\n",
    "        self.infos = {agent: {} for agent in self.agents}\n",
    "\n",
    "        self.state = {agent: self._none for agent in self.agents}\n",
    "        self.observations = {\n",
    "            agent: [self._none] * len(self.possible_agents)\n",
    "            for agent in self.agents\n",
    "        }\n",
    "\n",
    "        self.history = [0] * (2 * 5)\n",
    "\n",
    "        self.num_moves = 0\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Renders the environment. In human mode, it can print to terminal, open\n",
    "        up a graphical window, or open up some other display that a human can see and understand.\n",
    "        \"\"\"\n",
    "        if self.render_mode is None:\n",
    "            gymnasium.logger.warn(\n",
    "                \"You are calling render method without specifying any render mode.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        if len(self.agents) == 2:\n",
    "            string = \"Current state: Agent1: {} , Agent2: {}\".format(\n",
    "                self._moves[self.state[self.agents[0]]],\n",
    "                self._moves[self.state[self.agents[1]]],\n",
    "            )\n",
    "        else:\n",
    "            string = \"Game over\"\n",
    "        print(string)\n",
    "\n",
    "    def observe(self, agent):\n",
    "        # observation of one agent is the previous state of the other\n",
    "        return np.array(self.observations[agent])\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self, seed=None, return_info=False, options=None):\n",
    "        self.reinit()\n",
    "\n",
    "    def step(self, action):\n",
    "        if (\n",
    "            self.terminations[self.agent_selection]\n",
    "            or self.truncations[self.agent_selection]\n",
    "        ):\n",
    "            self._was_dead_step(action)\n",
    "            return\n",
    "\n",
    "        agent = self.agent_selection\n",
    "\n",
    "        self.state[self.agent_selection] = action\n",
    "\n",
    "        # collect reward if it is the last agent to act\n",
    "\n",
    "        if self._agent_selector.is_last():\n",
    "            (\n",
    "                self.rewards[self.agents[0]],\n",
    "                self.rewards[self.agents[1]],\n",
    "            ) = self.game.payoff[\n",
    "                (self.state[self.agents[0]], self.state[self.agents[1]])\n",
    "            ]\n",
    "\n",
    "            self.num_moves += 1\n",
    "            self.truncations = {\n",
    "                agent: self.num_moves >= self.max_cycles\n",
    "                for agent in self.agents\n",
    "            }\n",
    "\n",
    "            # observe the current state\n",
    "            for i in self.agents:\n",
    "                self.observations[i] = list(\n",
    "                    self.state.values()\n",
    "                )  # TODO: consider switching the board\n",
    "        else:\n",
    "            self.state[\n",
    "                self.agents[1 - self.agent_name_mapping[agent]]\n",
    "            ] = self._none\n",
    "            self._clear_rewards()\n",
    "\n",
    "        self._cumulative_rewards[self.agent_selection] = 0\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        self._accumulate_rewards()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SEED = 0\n",
    "    if SEED is not None:\n",
    "        np.random.seed(SEED)\n",
    "    # from pettingzoo.test import parallel_api_test\n",
    "\n",
    "    env = parallel_env(render_mode=\"human\")\n",
    "    # parallel_api_test(env, num_cycles=1000)\n",
    "\n",
    "    # Reset the environment and get the initial observation\n",
    "    obs = env.reset()\n",
    "\n",
    "    # Run the environment for 10 steps\n",
    "    for _ in range(10):\n",
    "        # Sample a random action\n",
    "        actions = {\"player_\" + str(i): np.random.randint(2) for i in range(2)}\n",
    "\n",
    "        # Step the environment and get the reward, observation, and done flag\n",
    "        observations, rewards, terminations, truncations, infos = env.step(\n",
    "            actions\n",
    "        )\n",
    "\n",
    "        # Print the reward\n",
    "        # print(rewards)\n",
    "        print(\"observations: \", rewards)\n",
    "        # If the game is over, reset the environment\n",
    "        if terminations[\"player_0\"]:\n",
    "            obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc477f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
